{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0rytU6wDnTvj6gDAeALsB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wanglingxiao123/remote-tset/blob/main/Langsmith_test_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UK6r4KfK07j",
        "outputId": "cac47aef-7538-43c9-a256-1789b7532a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.3 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet langchain==0.0.235 openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY']='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'\n",
        "os.environ['LANGCHAIN_TRACING_V2']='true'\n",
        "os.environ['LANGCHAIN_ENDPOINT']='https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_API_KEY']='ls__58e89b77ac2844588a8ab4bfb62bf574'\n",
        "os.environ['LANGCHAIN_PROJECT']='default'"
      ],
      "metadata": {
        "id": "LOzl6QpxK3OU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat=ChatOpenAI(temperature=0)\n",
        "response=chat([HumanMessage(content=\"Hello Langchain!\")])\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSh0XCfUMlTr",
        "outputId": "483c1057-676d-4461-e98d-3938ac2ab2b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='Hello! How can I assist you today?' additional_kwargs={} example=False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat=ChatOpenAI(temperature=0)\n",
        "response=chat([HumanMessage(content=\"你喜欢听什么类型的音乐\")])\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gtFAoPkOgOs",
        "outputId": "2d37af16-c5c5-4f67-fe08-f2aa4165f311"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='作为一个AI助手，我没有个人的喜好和偏好。但是，我可以为您提供各种类型的音乐推荐，例如流行音乐、摇滚音乐、古典音乐、嘻哈音乐、电子音乐等。您有任何特定的音乐类型或艺术家吗？' additional_kwargs={} example=False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat=ChatOpenAI(temperature=0)\n",
        "response=chat([HumanMessage(content=\"你喜欢吃甜食吗\")])\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeibapJ2dWr2",
        "outputId": "7670c1d6-c239-458f-cf45-a080465a936d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /runs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='作为一个AI助手，我没有口味和喜好，所以无法回答这个问题。但是，很多人喜欢吃甜食，因为甜食可以带来愉悦的味觉体验。' additional_kwargs={} example=False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from typing import List, Optional, Tuple\n",
        "\n",
        "import openai\n",
        "from langsmith.run_helpers import traceable\n",
        "\n",
        "\n",
        "# We will label this function as an 'llm' call to better organize it\n",
        "@traceable(run_type=\"llm\")\n",
        "def call_openai(data: List[dict], model: str = \"gpt-3.5-turbo\", temperature: float = 0.0) -> str:\n",
        "    return openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=data,\n",
        "        temperature=temperature,\n",
        "    ).choices[0].message.content\n",
        "\n",
        "\n",
        "# The 'chain' run_type can correspond to any function and is the most common\n",
        "@traceable(run_type=\"chain\")\n",
        "def argument_generator(query: str, additional_description: str = \"\") -> str:\n",
        "    return call_openai(\n",
        "        [\n",
        "            {\"role\": \"system\", \"content\": f\"You are a debater making an argument on a topic.\"\n",
        "             f\"{additional_description}\"\n",
        "             f\" The current time is {datetime.now()}\"},\n",
        "            {\"role\": \"user\", \"content\": f\"The discussion topic is {query}\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "@traceable(run_type=\"chain\")\n",
        "def critic(argument: str) -> str:\n",
        "    return call_openai(\n",
        "        [\n",
        "            {\"role\": \"system\", \"content\": f\"You are a critic.\"\n",
        "           \"\\nWhat unresolved questions or criticism do you have after reading the following argument?\"\n",
        "            \"Provide a concise summary of your feedback.\"},\n",
        "            {\"role\": \"system\", \"content\": argument}\n",
        "\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "@traceable(run_type=\"chain\")\n",
        "def refiner(query: str, additional_description: str, current_arg: str, criticism: str) -> str:\n",
        "    return call_openai(\n",
        "        [\n",
        "            {\"role\": \"system\", \"content\": f\"You are a debater making an argument on a topic.\"\n",
        "             f\"{additional_description}\"\n",
        "             f\" The current time is {datetime.now()}\"},\n",
        "            {\"role\": \"user\", \"content\": f\"The discussion topic is {query}\"},\n",
        "            {\"role\": \"assistant\", \"content\": current_arg},\n",
        "            {\"role\": \"user\", \"content\": criticism},\n",
        "            {\"role\": \"system\", \"content\": \"Please generate a new argument that incorporates the feedback from the user.\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "@traceable(run_type=\"chain\")\n",
        "def argument_chain(query: str, additional_description: str = \"\") -> str:\n",
        "    argument = argument_generator(query, additional_description)\n",
        "    criticism = critic(argument)\n",
        "    return refiner(query, additional_description, argument, criticism)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdN9gXxXjpdv",
        "outputId": "0498bfdf-0cd4-4b21-d217-d834bac6fdf9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.run_helpers:The @traceable decorator is experimental and will likely see breaking changes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = argument_chain(\n",
        "    \"Whether sunshine is good for you.\",\n",
        "    additional_description=\"Provide a concise, few sentence argument on why sunshine is good for you.\",\n",
        ")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLcBjOwUjq9A",
        "outputId": "9637cb31-0c39-452e-cdc7-ea9547f1cc38"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "While it is important to acknowledge the potential risks of excessive sun exposure, it is undeniable that moderate and responsible exposure to sunshine offers numerous benefits. Sunlight is a natural source of vitamin D, which plays a crucial role in maintaining bone health, supporting immune function, and promoting mental well-being. By practicing sun safety measures, such as wearing sunscreen and seeking shade during peak hours, individuals can enjoy the positive effects of sunshine while minimizing the potential risks. Additionally, alternative sources of vitamin D, such as fortified foods and supplements, can be incorporated into one's routine to maintain overall health.\n"
          ]
        }
      ]
    }
  ]
}